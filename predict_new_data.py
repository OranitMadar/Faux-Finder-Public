import pandas as pd
import numpy as np
import tensorflow as tf
from keras.models import load_model
from keras.api.layers import TextVectorization
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# ×”×•×¨×“×ª ××©××‘×™×
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

# × ×™×§×•×™ ×˜×§×¡×˜
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
def clean_text(text):
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", "", text)
    text = re.sub(r"@\w+|#\w+", "", text)
    text = re.sub(r"[^a-z\s]", "", text)
    text = re.sub(r"(.)\1{2,}", r"\1", text)
    words = nltk.word_tokenize(text)
    words = [word for word in words if word not in stop_words]
    words = [lemmatizer.lemmatize(word) for word in words]
    return " ".join(words)

# ×©×œ×‘ 1: ×˜×¢×Ÿ ××ª ×”××•×“×œ
model = load_model("final_train.keras")

# ×©×œ×‘ 2: ×˜×¢×Ÿ ××ª ×”×“××˜××¡×˜ ×”×—×“×©
df = pd.read_csv("final_eval_dataset.csv")
df["text"] = df["text"].astype(str).apply(clean_text)

# ×©×œ×‘ 3: ×”×›× ×ª ×•×§×˜×•×¨×™×–×¦×™×” (×× ×œ× × ×©××¨×”)
vectorization = TextVectorization(max_tokens=20000, output_sequence_length=150)
vectorization.adapt(df["text"])

# ×™×¦×™×¨×ª ×˜× ×¡×•×¨ ×©×œ ×˜×§×¡×˜×™× ×•×ª×•×•×™×•×ª
text_label_ds = tf.data.Dataset.from_tensor_slices((df["text"], df["label"])).batch(32)

# ×—×™×©×•×‘ loss
loss, _ = model.evaluate(text_label_ds, verbose=0)
print(f"ğŸ§® Loss: {loss:.4f}")

# ×™×¦×™×¨×ª ×˜× ×¡×•×¨ ×©×œ ×˜×§×¡×˜×™× ×œ×‘×“ (×¢×‘×•×¨ predict)
text_ds = tf.data.Dataset.from_tensor_slices(df["text"]).batch(32)

# ×©×œ×‘ 5: × ×™×‘×•×™
probs = model.predict(text_ds)
df["score"] = probs.flatten()
df["predicted_label"] = (df["score"] >= 0.5).astype(int)

# ×©×œ×‘ 6: ×—×™×©×•×‘ ×‘×™×¦×•×¢×™× (×× ×™×© ×ª×•×•×™×•×ª ×××ª)
if "label" in df.columns:
    y_true = df["label"].astype(int).values
    y_pred = df["predicted_label"].values

    cm = confusion_matrix(y_true, y_pred)
    TN, FP, FN, TP = cm.ravel()

    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)

    print("\nğŸ“Š ×ª×•×¦××ª ×”××•×“×œ ×¢×œ ×“××˜×”×¡×˜ ×—×“×©:")
    print(f"âœ… True Positives: {TP}")
    print(f"âŒ False Positives: {FP}")
    print(f"âŒ False Negatives: {FN}")
    print(f"âœ… True Negatives: {TN}")
    print(f"ğŸ“Œ Prediction real news (×¡×”\"×›): {sum(y_pred)}")

    print("\nğŸ“ˆ ××“×“×™×:")
    print(f"ğŸ¯ Accuracy:  {accuracy:.4f}")
    print(f"ğŸ¯ Precision: {precision:.4f}")
    print(f"ğŸ” Recall:    {recall:.4f}")
    print(f"ğŸ’¡ F1 Score:  {f1:.4f}")
else:
    print("âš ï¸ ×œ× × ××¦××” ×¢××•×“×ª 'label' ×‘×“××˜×”×¡×˜ â€” ×œ× × ×™×ª×Ÿ ×œ×—×©×‘ ×‘×™×¦×•×¢×™×.")
